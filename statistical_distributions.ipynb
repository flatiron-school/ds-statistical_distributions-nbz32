{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Statistical-Distributions\" data-toc-modified-id=\"Statistical-Distributions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Statistical Distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Agenda:\" data-toc-modified-id=\"Agenda:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Agenda:</a></span></li><li><span><a href=\"#What-is-a-statistical-distribution?\" data-toc-modified-id=\"What-is-a-statistical-distribution?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>What is a statistical distribution?</a></span></li><li><span><a href=\"#Discrete-vs.-Continuous\" data-toc-modified-id=\"Discrete-vs.-Continuous-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Discrete vs. Continuous</a></span><ul class=\"toc-item\"><li><span><a href=\"#Discrete\" data-toc-modified-id=\"Discrete-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Discrete</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples-of-discrete-distributions:\" data-toc-modified-id=\"Examples-of-discrete-distributions:-1.3.1.1\"><span class=\"toc-item-num\">1.3.1.1&nbsp;&nbsp;</span>Examples of discrete distributions:</a></span></li></ul></li><li><span><a href=\"#Continuous\" data-toc-modified-id=\"Continuous-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Continuous</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples-of-continuous-distributions\" data-toc-modified-id=\"Examples-of-continuous-distributions-1.3.2.1\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Examples of continuous distributions</a></span></li></ul></li></ul></li><li><span><a href=\"#PMFs,-PDFs,-CDFs\" data-toc-modified-id=\"PMFs,-PDFs,-CDFs-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>PMFs, PDFs, CDFs</a></span><ul class=\"toc-item\"><li><span><a href=\"#PMF:-Probability-Mass-Function\" data-toc-modified-id=\"PMF:-Probability-Mass-Function-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>PMF: Probability Mass Function</a></span></li><li><span><a href=\"#Expected-Value/Mean\" data-toc-modified-id=\"Expected-Value/Mean-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Expected Value/Mean</a></span></li><li><span><a href=\"#Variance/Standard-Deviation\" data-toc-modified-id=\"Variance/Standard-Deviation-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Variance/Standard Deviation</a></span></li><li><span><a href=\"#Uniform-Distribution\" data-toc-modified-id=\"Uniform-Distribution-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Uniform Distribution</a></span></li></ul></li><li><span><a href=\"#PDF:-Probability-Density-Function\" data-toc-modified-id=\"PDF:-Probability-Density-Function-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>PDF: Probability Density Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Expected-value-and-variance-for-PDFs:\" data-toc-modified-id=\"Expected-value-and-variance-for-PDFs:-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Expected value and variance for PDFs:</a></span></li><li><span><a href=\"#Describing-the-PDF\" data-toc-modified-id=\"Describing-the-PDF-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Describing the PDF</a></span></li><li><span><a href=\"#Skewed-Distributions\" data-toc-modified-id=\"Skewed-Distributions-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>Skewed Distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transforming--Right/Positively-Skewed-Data\" data-toc-modified-id=\"Transforming--Right/Positively-Skewed-Data-1.5.3.1\"><span class=\"toc-item-num\">1.5.3.1&nbsp;&nbsp;</span>Transforming  Right/Positively Skewed Data</a></span></li><li><span><a href=\"#Transforming-Left/Negatively-Skewed-Data\" data-toc-modified-id=\"Transforming-Left/Negatively-Skewed-Data-1.5.3.2\"><span class=\"toc-item-num\">1.5.3.2&nbsp;&nbsp;</span>Transforming Left/Negatively Skewed Data</a></span></li></ul></li><li><span><a href=\"#Kurtosis\" data-toc-modified-id=\"Kurtosis-1.5.4\"><span class=\"toc-item-num\">1.5.4&nbsp;&nbsp;</span>Kurtosis</a></span></li></ul></li><li><span><a href=\"#CDF:-Cumulative-Distribution-Function\" data-toc-modified-id=\"CDF:-Cumulative-Distribution-Function-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>CDF: Cumulative Distribution Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Some-Things-to-Be-Aware-Of\" data-toc-modified-id=\"Some-Things-to-Be-Aware-Of-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Some Things to Be Aware Of</a></span></li><li><span><a href=\"#Example:-Using-CDF-&amp;-comparison-to-PDF\" data-toc-modified-id=\"Example:-Using-CDF-&amp;-comparison-to-PDF-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Example: Using CDF &amp; comparison to PDF</a></span></li><li><span><a href=\"#So-Why-Is-It-Useful?\" data-toc-modified-id=\"So-Why-Is-It-Useful?-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span>So Why Is It Useful?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quickly-identify-key-values\" data-toc-modified-id=\"Quickly-identify-key-values-1.6.3.1\"><span class=\"toc-item-num\">1.6.3.1&nbsp;&nbsp;</span>Quickly identify key values</a></span></li><li><span><a href=\"#Outliers-can-be-more-obvious\" data-toc-modified-id=\"Outliers-can-be-more-obvious-1.6.3.2\"><span class=\"toc-item-num\">1.6.3.2&nbsp;&nbsp;</span>Outliers can be more obvious</a></span></li><li><span><a href=\"#Identifying-clusters\" data-toc-modified-id=\"Identifying-clusters-1.6.3.3\"><span class=\"toc-item-num\">1.6.3.3&nbsp;&nbsp;</span>Identifying clusters</a></span></li><li><span><a href=\"#Relative-easy-to-view-multiple-distributions\" data-toc-modified-id=\"Relative-easy-to-view-multiple-distributions-1.6.3.4\"><span class=\"toc-item-num\">1.6.3.4&nbsp;&nbsp;</span>Relative easy to view multiple distributions</a></span></li></ul></li></ul></li><li><span><a href=\"#Common-Discrete-Distributions\" data-toc-modified-id=\"Common-Discrete-Distributions-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Common Discrete Distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bernoulli-and-Binomial-Distributions\" data-toc-modified-id=\"Bernoulli-and-Binomial-Distributions-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>Bernoulli and Binomial Distributions</a></span></li><li><span><a href=\"#Binomial-Distribution\" data-toc-modified-id=\"Binomial-Distribution-1.7.2\"><span class=\"toc-item-num\">1.7.2&nbsp;&nbsp;</span>Binomial Distribution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Game-Time!\" data-toc-modified-id=\"Game-Time!-1.7.2.1\"><span class=\"toc-item-num\">1.7.2.1&nbsp;&nbsp;</span>Game Time!</a></span></li><li><span><a href=\"#But-What's-Real:-Simulation-Time!\" data-toc-modified-id=\"But-What's-Real:-Simulation-Time!-1.7.2.2\"><span class=\"toc-item-num\">1.7.2.2&nbsp;&nbsp;</span>But What's <em>Real</em>: Simulation Time!</a></span></li></ul></li><li><span><a href=\"#Poisson-Distribution\" data-toc-modified-id=\"Poisson-Distribution-1.7.3\"><span class=\"toc-item-num\">1.7.3&nbsp;&nbsp;</span>Poisson Distribution</a></span></li></ul></li><li><span><a href=\"#Normal-Distribution\" data-toc-modified-id=\"Normal-Distribution-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Normal Distribution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-Normal-Distribution\" data-toc-modified-id=\"Standard-Normal-Distribution-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Standard Normal Distribution</a></span></li><li><span><a href=\"#Empirical-Rule\" data-toc-modified-id=\"Empirical-Rule-1.8.2\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>Empirical Rule</a></span></li><li><span><a href=\"#$z$-Score\" data-toc-modified-id=\"$z$-Score-1.8.3\"><span class=\"toc-item-num\">1.8.3&nbsp;&nbsp;</span>$z$-Score</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-1.8.3.1\"><span class=\"toc-item-num\">1.8.3.1&nbsp;&nbsp;</span>Exercises</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/distributions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWBAT:\n",
    "- 1. Describe the difference between discrete and continuous random variables;\n",
    "- 2. Describe the difference between PMFs, PDFs, and CDFs;\n",
    "- 3. Describe the Bernoulli and Binomial Distributions;\n",
    "- 4. Describe the Normal Distribution and the associated Empirical Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a statistical distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A statistical distribution is a representation of the frequencies of potential events or the percentage of time each event occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete vs. Continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn about a variety of different probability distributions, but before we do so, we need to establish the difference between **discrete** and **continuous** variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  With discrete distributions, the values can only take a finite set of values.  Take, for example, a roll of a single six-sided die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/uniform.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - There are 6 possible outcomes of the roll. As you see on the PMF plot, the bars which represent probability do not touch, suggesting non-integer numbers between 1 and 6 are not possible results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of discrete distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Uniform Distribution**\n",
    "    - occurs when all possible outcomes are equally likely.\n",
    "- **Bernoulli Distribution**\n",
    "    - represents the probability of success for a certain experiment (binary outcome).\n",
    "- **Binomial Distribution**\n",
    "    - represents the probability of observing a specific number of successes (Bernoulli trials) in a specific number of trials.\n",
    "- **Poisson Distribution**\n",
    "    - represents the probability of ð‘› events in a given time period when the overall rate of occurrence is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a continuous distribution, the set of possible results is an infinite set of values within a range. Think about measuring the length of something. The reported measurement can always be more or less precise.\n",
    "\n",
    "![](images/pdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of continuous distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Continuous Uniform**;\n",
    "- **Normal or Gaussian**;\n",
    "- **Exponential**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMFs, PDFs, CDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF: Probability Mass Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\bf{probability\\ mass\\ function\\ (pmf)}$ for a random variable gives, at any value $k$, the probability that the random variable takes the value $k$. Suppose, for example, that I have a jar full of lottery balls containing:\n",
    "- 50 \"1\"s,\n",
    "- 25 \"2\"s,\n",
    "- 15 \"3\"s,\n",
    "- 10 \"4\"s\n",
    "\n",
    "We then represent this function in a plot like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number, we calculate the probability that pull it from the jar by dividing\n",
    "\n",
    "numbers = range(1, 5)\n",
    "counts = [50, 25, 15, 10]\n",
    "\n",
    "# calculate the probs by dividing each count by the total number of balls.\n",
    "\n",
    "probs = [count/sum(counts) for count in counts]\n",
    "\n",
    "lotto_dict = {number: prob for number, prob in zip(numbers, probs)}\n",
    "lotto_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot here!\n",
    "\n",
    "x = list(lotto_dict.keys())\n",
    "y = list(lotto_dict.values())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.plot(x, y, 'bo', ms=8, label='lotto pmf')\n",
    "ax.vlines(x, 0, y, 'r', lw=5)\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Value/Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value, or the mean, describes the 'center' of the distribution (you may hear this called the first moment).  The 'center' refers loosely to the middle-values of a distribution, and is measured more precisely by notions like the mean, the median, and the mode.\n",
    "\n",
    "For a discrete distribution, working from the vantage point of a collected sample of n data points:\n",
    "\n",
    "mean = $\\Large\\mu = \\frac{\\Sigma^n_{i = 1}x_i}{n}$\n",
    "\n",
    "If we are working from the vantage point of known probabilities, the mean is referred to as the expected value. The expected value of a discrete distribution is the weighted sum of all values of x, where the weight is their probability.\n",
    " \n",
    "The expected value of the Lotto example is:\n",
    "${\\displaystyle \\operatorname {E} [X]= \\Sigma^n_{i=1}p(x_i)x_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance/Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance describes the spread of the data (it is also referred to as the second moment).  The 'spread' refers loosely to how far away the more extreme values are from the center.\n",
    "\n",
    "Standard deviation is the square root of variance, and effectively measures the *average distance away from the mean*.\n",
    "\n",
    "From the standpoint of a sample, the variance of a discrete distribution of n data points is:\n",
    "\n",
    "std = $\\Large\\sigma = \\sqrt{\\frac{\\Sigma^n_{i = 1}(x_i - \\mu)^2}{n}}$\n",
    "\n",
    "\n",
    "Variance is the expectation of the squared deviation of a random variable from its mean.\n",
    "\n",
    "For our Lotto PMF, that means:\n",
    "\n",
    " $ \\Large E((X-\\mu)^2) = \\sigma^2 = \\Sigma^n_{i=1}p(x_i)(x_i - \\mu)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uniform distribution describes a set of discrete outcomes whose probabilities are all equally likely.\n",
    "\n",
    "A common example is the roll of a die.  \n",
    "\n",
    "The pmf of a discrete uniform distribution is simply:\n",
    "\n",
    "$ f(x)=\\frac{1}{n} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected value for the roll of a 12-sided die\n",
    "\n",
    "expected_value = sum([1/12 * n for n in range(1, 13)])\n",
    "print(f'Expected value: {expected_value}')\n",
    "\n",
    "# variance for a roll of a 12-sided die\n",
    "\n",
    "variance = sum([1/12 * (n - expected_value)**2 for n in range(1, 13)])\n",
    "print(f'Variance: {variance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF: Probability Density Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Probability density functions are similar to PMFs, in that they describe the probability of a result within a range of values. But where PMFs are appropriate for discrete variables and so can be descibed with barplots, PDFs are smooth curves that describe continuous random variables.  \n",
    "\n",
    "![](images/pdf_temp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of a pdf as a bunch of bars of probabilities getting smaller and smaller until each neighbor is indistinguishable from its neighbor.\n",
    "\n",
    "It is then intuitive that you cannot calculate expected value and variance in the same way as we did with pmfs.  Instead, we have to integrate over the entirety of the curve to calculate the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected value and variance for PDFs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/exp_v_pdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/pdf_inter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating the mean and standard deviation by hand, we will rather get familiar with how they affect the shape of our PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of our PDF affects where it is centered on the x-axis.  In `numpy` and `stats`, mean is denoted by the \"loc\" parameter.\n",
    "\n",
    "The two plots below have the same shape, but different centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 0\n",
    "z_curve = np.linspace(stats.norm(mean, 1).ppf(0.01),\n",
    "             stats.norm(mean, 1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, 1).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "z_curve = np.linspace(stats.norm(mean, 1).ppf(0.01),\n",
    "             stats.norm(mean, 1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, 1).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions differing in mean\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of our plots describes how closely the points are gathered around the mean.  Low variance means tight and skinny, high variance short and wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 1\n",
    "var = 1\n",
    "z_curve = np.linspace(stats.norm(mean, var).ppf(0.01),\n",
    "             stats.norm(mean, var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, var).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "var = 3\n",
    "z_curve = np.linspace(stats.norm(mean, var).ppf(0.01),\n",
    "             stats.norm(mean, var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, var).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions differing in variance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the third moment of a statistical distribution: skew. A skew of zero is perfectly symmetrical about the mean.   \n",
    "\n",
    "![skew](images/skew.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check skewness with scipy\n",
    "\n",
    "z_curve = np.random.normal(0, 1, 1000)\n",
    "print(stats.skew(z_curve))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming  Right/Positively Skewed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to transform our skewed data to make it approach symmetry.\n",
    "\n",
    "Common transformations of this data include "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Root Transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x \\rightarrow\\sqrt[n]{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logarithmic Transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x \\rightarrow\\log_n{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Left/Negatively Skewed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Power Transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x\\rightarrow x^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kurtosis](images/kurtosis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDF: Cumulative Distribution Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/cdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution function describes the probability that your result will be of a value equal to or below a certain value. It can apply to both discrete or continuous functions.\n",
    "\n",
    "For the scenario above, the CDF would describe the probability of drawing a ball equal to or below a certain number.  \n",
    "\n",
    "In order to create the CDF from a sample, we:\n",
    "- align the values from least to greatest\n",
    "- for each value, count the number of values that are less than or equal to the current value\n",
    "- divide that count by the total number of values\n",
    "\n",
    "The CDF of the Lotto example plots how likely we are to get a ball less than or equal to a given example. \n",
    "\n",
    "Let's create the CDF for our Lotto example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the values\n",
    "\n",
    "lotto_dict = {0:0, 1:50, 2:25, 3:15, 4:10}\n",
    "values = list(lotto_dict.keys())\n",
    "\n",
    "# count the number of values that are less than\n",
    "# or equal to the current value\n",
    "\n",
    "count_less_than_equal = np.cumsum(list(lotto_dict.values()))\n",
    "\n",
    "# divide by total number of values\n",
    "prob_less_than_or_equal = count_less_than_equal/sum(lotto_dict.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(values, prob_less_than_or_equal, 'bo', ms=8, label='lotto pdf')\n",
    "for i in range(0, 5):\n",
    "    ax.hlines(prob_less_than_or_equal[i], i,i+1, 'r', lw=5,)\n",
    "for i in range(0, 4):\n",
    "    ax.vlines(i+1, prob_less_than_or_equal[i+1],\n",
    "              prob_less_than_or_equal[i], linestyles='dotted')\n",
    "ax.legend(loc='best' )\n",
    "ax.set_ylim(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Things to Be Aware Of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For continuous random variables, obtaining probabilities for observing a specific outcome is not possible \n",
    "- Be careful with interpretation of PDF\n",
    "\n",
    "We can use the CDF to learn the probability that a variable will be less than or equal to a given value.\n",
    "\n",
    "Typically, you'll see something like this equation associated with the CDF:\n",
    "\n",
    "$$F(x) = P(X\\leq x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Using CDF & comparison to PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following normal distributions of heights (more on the normal distribution below).\n",
    "\n",
    "The PDF and the CDF look like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sorted(stats.norm.rvs(loc=70, scale=3, size=1000))\n",
    "r_cdf = stats.norm.cdf(r, loc=70, scale=3)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.kdeplot(r, ax=ax1, shade=True)\n",
    "ax1.set_title('PDF of Male Height in US')\n",
    "\n",
    "ax2.plot(r, r_cdf, color='g')\n",
    "ax2.set_title('CDF of Male Height in the US');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide `numpy` with the underlying parameters of our distribution, we can calculate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the probability that a value falls below a specified value\n",
    "\n",
    "r = stats.norm(70, 3)\n",
    "r.cdf(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the probability that a value falls between two specified values\n",
    "\n",
    "r = stats.norm(70, 3)\n",
    "r.cdf(73) - r.cdf(67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the value associated with a specfic percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.ppf(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So Why Is It Useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might look at the CDF and wonder if it's a shadow of my beloved histogram. But there are some good use cases for this way of visualizing the CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's define some data\n",
    "domain_x = np.linspace(-1,1,100)\n",
    "norm_dist = stats.norm.rvs(0,0.3,domain_x.shape)\n",
    "norm_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quickly identify key values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding features like the median, minimum, maximum, and quartiles are easy to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax_pdf,ax_cdf) = plt.subplots(nrows=1,ncols=2,figsize=(12,4))\n",
    "\n",
    "###### Histogram (PDF)\n",
    "ax_pdf = sns.histplot(x=norm_dist, ax=ax_pdf, alpha=0.4)\n",
    "# You can also see the PDF if you want\n",
    "# ax_pdf = sns.kdeplot(x=out, cumulative=False, ax=ax_pdf)\n",
    "# Median\n",
    "ax_pdf.vlines(\n",
    "    x=np.median(norm_dist),\n",
    "    ymin=0,\n",
    "    ymax=10,\n",
    "    linestyles='--',\n",
    "    color='red'      \n",
    ")\n",
    "# 25th-percentile\n",
    "ax_pdf.vlines(\n",
    "    x=np.quantile(norm_dist, 0.25),\n",
    "    ymin=0,\n",
    "    ymax=10,\n",
    "    linestyles='--',\n",
    "    color='purple'      \n",
    ")\n",
    "# 75th-percentile\n",
    "ax_pdf.vlines(\n",
    "    x=np.quantile(norm_dist, 0.75),\n",
    "    ymin=0,\n",
    "    ymax=10,\n",
    "    linestyles='--',\n",
    "    color='purple'      \n",
    ")\n",
    "\n",
    "###### CDF\n",
    "ax_cdf = sns.kdeplot(x=norm_dist, cumulative=True, ax=ax_cdf)\n",
    "# Median\n",
    "ax_cdf.hlines(\n",
    "    y=0.5,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    linestyles='--',\n",
    "    color='red'\n",
    ")\n",
    "# 25th-percentile\n",
    "ax_cdf.hlines(\n",
    "    y=0.25,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    linestyles='--',\n",
    "    color='purple'\n",
    ")\n",
    "# 75th-percentile\n",
    "ax_cdf.hlines(\n",
    "    y=0.75,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    linestyles='--',\n",
    "    color='purple'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers can be more obvious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations with outliers can be a little tricky. Take a look at your histogram. With outliers, it might be identified but can distort our focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an outlier\n",
    "norm_with_outliers = np.append(norm_dist, 5*np.abs(np.random.randn(5)))\n",
    "norm_with_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax0,ax1) = plt.subplots(1,2, figsize=(12,4))\n",
    "# Showing the outliers\n",
    "sns.histplot(x=norm_with_outliers, alpha=0.4, ax=ax0)\n",
    "# Ignoring outliers\n",
    "ax1=sns.histplot(x=norm_with_outliers, alpha=0.4, ax=ax1)\n",
    "ax1.set_xlim(right=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a worst-case, you might not notice the outliers because it gets swallowed up due by a bin because of the number of bins or bin width parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using a CDF, it can be a lot easier to identify when there is an extreme value even if we scale the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax0,ax1) = plt.subplots(1,2, figsize=(12,4))\n",
    "# Showing the outliers\n",
    "ax0 = sns.kdeplot(x=norm_with_outliers, cumulative=True, ax=ax0)\n",
    "ax0.hlines(1,xmin=-1,xmax=3,color='red',linestyles='--')\n",
    "# Ignoring outliers\n",
    "ax1 = sns.kdeplot(x=norm_with_outliers, cumulative=True, ax=ax1)\n",
    "ax1.hlines(1,xmin=-1,xmax=1,color='red',linestyles='--')\n",
    "ax1.set_xlim(right=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically not hard with a histogram. But you can also see it in CDFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_x = np.linspace(-1,1,100)\n",
    "norm_dist0 = stats.norm.rvs(0,0.3,domain_x.shape)\n",
    "norm_dist1 = stats.norm.rvs(2,0.2,domain_x.shape)\n",
    "two_dist = np.append(norm_dist0,norm_dist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax0,ax1,ax2) = plt.subplots(3,2, figsize=(12,12))\n",
    "# Histogram\n",
    "ax=sns.histplot(x=norm_dist0, alpha=0.4, ax=ax0[0])\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.histplot(x=norm_dist1, alpha=0.4, ax=ax1[0])\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.histplot(x=two_dist, alpha=0.4, ax=ax2[0])\n",
    "ax.set_xlim(-1,3.5)\n",
    "\n",
    "# CDF\n",
    "ax=sns.kdeplot(x=norm_dist0, alpha=0.4, ax=ax0[1], cumulative=True)\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.kdeplot(x=norm_dist1, alpha=0.4, ax=ax1[1], cumulative=True)\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.kdeplot(x=two_dist, alpha=0.4, ax=ax2[1], cumulative=True)\n",
    "ax.set_xlim(-1,3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative easy to view multiple distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dist0 = stats.norm.rvs(0,0.3,domain_x.shape)\n",
    "norm_dist1 = stats.norm.rvs(0,0.2,domain_x.shape)\n",
    "norm_dist2 = stats.norm.rvs(0.3,0.2,domain_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax0,ax1) = plt.subplots(2,1, figsize=(12,12))\n",
    "# Histogram\n",
    "ax=sns.histplot(x=norm_dist0, alpha=0.4, ax=ax0, color='red')\n",
    "ax=sns.histplot(x=norm_dist1, alpha=0.4, ax=ax0, color='yellow')\n",
    "ax=sns.histplot(x=norm_dist2, alpha=0.4, ax=ax0, color='blue')\n",
    "\n",
    "# CDF\n",
    "ax=sns.kdeplot(x=norm_dist0, alpha=0.4, ax=ax1, cumulative=True, color='red')\n",
    "ax=sns.kdeplot(x=norm_dist1, alpha=0.4, ax=ax1, cumulative=True, color='yellow')\n",
    "ax=sns.kdeplot(x=norm_dist2, alpha=0.4, ax=ax1, cumulative=True, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Discrete Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know a few methods in visualizing distributions ðŸ“ŠðŸ‘€, we can start looking at different types of distributions.\n",
    "\n",
    "We can tell a lot about a distribution shape such as taking a guess of the mechanism that it took to generate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli and Binomial Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli Distribution is the discrete distribution that describes a two-outcome trial, such as a coin toss. The distribution is described by the probability $p$ of one random variable taking the value 1 and by the corrleative probability $q$, associated with 0 and taking the probability 1-p. \n",
    "\n",
    "PMF: \n",
    "${\\displaystyle {\\begin{cases}q=1-p&{\\text{if }}k=0\\\\p&{\\text{if }}k=1\\end{cases}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest example is, once again, a coin flip.  In this scenario, we define either heads or tails as a \"success\", and assume, if the coin is fair, the probability of success to be .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bernouli.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example would be a penalty kick in soccer.\n",
    "\n",
    "Let's assume the probability of scoring a goal is .75. Then the Bernoulli Distribution is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of scoring\n",
    "p = 0.75\n",
    "\n",
    "# probability of missing\n",
    "q = 1 - 0.75\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(['miss', 'score'],[q,p], color=['red','green'])\n",
    "ax.set_title('Bernouli Distribution of Penalty Kicks');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value is the probability of success, i.e. 0.75.\n",
    "\n",
    "The variance is:  \n",
    "$\\sigma^2 = (0.75)*(1-0.75) = 0.1875 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Binomial distribution describes the number of successes of a set of Bernoulli trials. For example, say we have an unfair coin with a probability of landing heads of 0.8. If our number of trials is 3, our PMF and CDF would look like what we see below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/binomial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the binomial, our Expected Value and Variance can be calculated like so:\n",
    "- Expected Value\n",
    "> $E(X) = np$ <br>\n",
    "- Variance\n",
    "> $Var(X) = np(1-p)$<br>\n",
    "\n",
    "If we want to see the probability of a certain number of successes, we use the pmf:\n",
    "\n",
    "$$\\Large f(x) = {n \\choose k}p^k(1 - p)^{n - k}$$\n",
    "\n",
    "Remember: ${n\\choose k} = \\frac{n!}{k!(n - k)!}$, the number of ways of choosing $k$ objects from a total of $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our penalty kick example. Suppose we consider a 10-kick set of penalty shots.\n",
    "\n",
    "The Binomial Distribution can tell me what the probability is that the shootout will result in exactly $k$ goals out of $n$ shots ($k < n$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "p = 0.75\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "x = np.arange(stats.binom.ppf(0.001, n, p),\n",
    "              stats.binom.ppf(0.999, n, p)+1)\n",
    "\n",
    "ax.plot(x, stats.binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\n",
    "ax.vlines(x, 0, stats.binom.pmf(x, n, p), 'r', linewidth=5,\n",
    "          label='pmf')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game Time! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a little game! We take a coin and flip it 10 times and see how many times we get heads over tails. Okay, so admittedly that's a boring game for most people (it's no video game). \n",
    "\n",
    "* But humoring me, how many times do we expect to see heads in those 10 flips?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> That should be pretty easy to reason. Since we have that handy-dandy equation from above to get $E(x)$ (or simply $np$) and get $10\\cdot 0.5 = 5$ for a fair coin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's level up! If we were to play this many times, how often would we expect to see 5 heads? What about 3 heads?\n",
    "\n",
    "> Well, that's just using the other handy-dandy equation ${n \\choose k}p^k(1 - p)^{n - k}$! That's the power of the binomial distribution! Let's plot this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot binomial for fair coin for n=10 flips\n",
    "n = 10\n",
    "p = 0.5\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "x = np.arange(0,n+1)\n",
    "\n",
    "ax.plot(x, stats.binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\n",
    "ax.vlines(x, 0, stats.binom.pmf(x, n, p), 'r', linewidth=5,\n",
    "          label='pmf')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now I said the coin was fair but if it wasn't? What what that look like for 10 flips? Well, we can plot all that out too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "ps = np.array([0.1,0.2,0.3,0.4,0.6,0.7])\n",
    "fig, axs = plt.subplots(ps.shape[0],1, figsize=(12, 12))\n",
    "x = np.arange(0,11)\n",
    "\n",
    "for ax,p in zip(axs,ps):\n",
    "    f_x = stats.binom.pmf(x, n, p)\n",
    "    ax.plot(x, f_x, 'bo', ms=8, label='binom pmf')\n",
    "    ax.vlines(x, 0, f_x, 'r', linewidth=5,\n",
    "              label='pmf')\n",
    "    ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But What's _Real_: Simulation Time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out some of these can actually just be simulated. Sort of like cheating ðŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a scenario where we observe a negative or positive review. We know that there is some probability $p$\n",
    "in getting a positive review (_success_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a probability of a positive review and how many reviews would we expect to see for a given $N$ reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate from so many total reviews with a certain probability\n",
    "def generate_reviews(n_outcomes, true_prob=0.9, n_trials=1):\n",
    "    '''Success or failure â†’ True or False\n",
    "    '''\n",
    "    outcomes_shape = (n_trials, n_outcomes)\n",
    "    outcomes = np.random.random_sample(size=outcomes_shape) < true_prob\n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_matching_our_success(N, p, n_trials): \n",
    "    # Create a trial of N reviews\n",
    "    trial = generate_reviews(n_outcomes=N, true_prob=p, n_trials=n_trials)\n",
    "    # Return number of successes\n",
    "    success_trial = np.sum(trial,axis=1)\n",
    "    return success_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tries in a trial (observed)\n",
    "N = 20\n",
    "p = 0.8\n",
    "\n",
    "n_trials = 100\n",
    "counts = num_matching_our_success(N, p, n_trials)\n",
    "ax = sns.histplot(x=counts, kde=True)\n",
    "ax.set_xlim(left=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXTRA: Probability of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we didn't know $p$, we could make a distribution to see what $p$ would best match our observed data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = {}\n",
    "# Number of tries in a trial (observed)\n",
    "observed_successes, N = 16, 20\n",
    "\n",
    "n_trials = 100_000\n",
    "\n",
    "# Define a probability\n",
    "for p in np.linspace(0,1,50,endpoint=False):\n",
    "    # Update list: What percent matched our observation\n",
    "    trial_successes = num_matching_our_success(N, p, n_trials)\n",
    "    probs[p] = np.sum(trial_successes == observed_successes)\n",
    "    \n",
    "sns.scatterplot(x=probs.keys(),y=probs.values())\n",
    "plt.vlines(probs.keys(),0, probs.values(), linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽµ***That graph is Poisson***ðŸŽµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Poisson distribution describes the probability of a certain number of a specific type of event occuring over a given interval. We assume that these events are probabilistically independent.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- number of visitors to a website over an hour\n",
    "- number of pieces of mail arriving at your door per day over a month\n",
    "- number of births in a hospital per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of the Poisson Distribution is governed by the rate parameter **$\\lambda$** (lambda):\n",
    "\n",
    "$\\Large\\lambda = \\frac{Avg\\ number\\ of\\ events}{period\\ of\\ time}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then our Poisson pmf is: ${\\displaystyle P(k)= {\\frac {\\lambda ^{k}e^{-\\lambda }}{k!}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the scenario where a website receives 100 hits per hour.\n",
    "\n",
    "Then we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 100\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "x = np.arange(stats.poisson.ppf(0.01, rate),\n",
    "              stats.poisson.ppf(0.99, rate))\n",
    "\n",
    "ax.plot(x, stats.poisson(rate).pmf(x), 'bo', ms=8, label='poisson pmf')\n",
    "ax.vlines(x, 0, stats.poisson(rate).pmf(x), 'r', linewidth=5,\n",
    "          label='Poisson Distribution:\\n Website Hits Over an Hour')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Poisson distribution has a unique characteristic:\n",
    "    \n",
    "$\\Large\\mu = \\sigma^2 = \\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The area under the curve up to the mean + 1sd\n",
    "# would be 84% of the total area\n",
    "\n",
    "stats.poisson.ppf(0.84, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution describes many phenomena. Think of anything that has a typical range:\n",
    "- human body temperatures\n",
    "- sizes of elephants\n",
    "- sizes of stars\n",
    "- populations of cities\n",
    "- IQ\n",
    "- heart rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among human beings, 98.6 degrees Fahrenheit is an _average_ body temperature. Many folks' temperatures won't measure _exactly_ 98.6 degrees, but most measurements will be _close_. It is much more common to have a body temperature close to 98.6 (whether slightly more or slightly less) than it is to have a body temperature far from 98.6 (whether significantly more or significantly less). This is a hallmark of a normally distributed variable.\n",
    "\n",
    "Similarly, there are large elephants and there are small elephants, but most elephants are near the average size.\n",
    "\n",
    "The normal distribution is _very_ common in nature (**Why?**) and will arise often in your work. Get to know it well!\n",
    "\n",
    "You will recognize it by its characteristic bell curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![normal_curve](images/IQ_normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see the notation \n",
    "\n",
    "$N(\\mu, \\sigma^2)$\n",
    "\n",
    "where N signifies that the distribution is normal, $\\mu$ is the mean, and $\\sigma^2$ is the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF of the normal curve is given by:\n",
    "\n",
    "$\\Large f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}exp\\left[\\frac{-(x - \\mu)^2}{2\\sigma^2}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mu = 0\n",
    "sigma = 1\n",
    "z_curve = np.linspace(stats.norm(mu,sigma).ppf(0.01),\n",
    "             stats.norm(mu,sigma).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mu,sigma).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/normal_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard normal distribution has a mean of 0 and variance of 1. This is also known as a z distribution. \n",
    "\n",
    "\n",
    "![norm_to_z](images/norm_to_z.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform the normal distribtion centered on 5\n",
    "# with a standard deviation of 2 into a standard normal\n",
    "\n",
    "normal_dist = np.random.normal(5, 2, 1000)\n",
    "z_dist = [(x - np.mean(normal_dist))/np.std(normal_dist) \n",
    "          for x in normal_dist]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(x=z_dist, ax=ax, kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/empirical_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rule states that 68% of the values of a normal distribution of data lie within 1 standard deviation of the mean, 95% within 2 stds, and 99.7 within three.  \n",
    "\n",
    "This makes it really quick to look at a normal distribution and understand where values tend to lie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/learn-co-students/dsc-0-09-12-gaussian-distributions-online-ds-ft-031119/blob/master/normalsd.jpg?raw=true' width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $z$-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A $z$-score for a data point x (in a normal distribution) is simply the distance to the mean in units of standard deviations. That is:\n",
    "\n",
    "$z = \\frac{x - \\mu}{\\sigma}$.\n",
    "\n",
    "By calculating the z-score of an individual point, we can see how unlikely a value is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a little site with some [interactive Gaussians](https://www.intmath.com/counting-probability/normal-distribution-graph-interactive.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider the distribution of heights of American women, with a mean of 65 inches and a standard deviation of 3.5 inches.\n",
    "\n",
    "> Calculate the z-score of a height of 75 inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What type of distribution would describe the following datasets?\n",
    "\n",
    "    - (a) results of rolling a die 100 times;\n",
    "    - (b) results of a random number generator;\n",
    "    - (c) results of random measurements of palm tree heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How would the salaries of New Yorkers likely be distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
