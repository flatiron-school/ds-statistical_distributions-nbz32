{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/distributions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda:\n",
    "   \n",
    "SWBAT:\n",
    "- 1. Describe the difference between discrete and continuous random variables;\n",
    "- 2. Describe the difference between PMFs, PDFs, and CDFs;\n",
    "- 3. Describe the Bernoulli and Binomial Distributions;\n",
    "- 4. Describe the Normal Distribution and the associated Empirical Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a statistical distribution?\n",
    "\n",
    "- A statistical distribution is a representation of the frequencies of potential events or the percentage of time each event occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete vs. Continuous\n",
    "\n",
    "We will learn about a variety of different probability distributions, but before we do so, we need to establish the difference between **discrete** and **continuous** variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete\n",
    "\n",
    ">  With discrete distributions, the values can only take a finite set of values.  Take, for example, a roll of a single six-sided die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/uniform.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - There are 6 possible outcomes of the roll. As you see on the PMF plot, the bars which represent probability do not touch, suggesting non-integer numbers between 1 and 6 are not possible results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of discrete distributions:\n",
    "\n",
    "- **Uniform Distribution**\n",
    "    - occurs when all possible outcomes are equally likely.\n",
    "- **Bernoulli Distribution**\n",
    "    - represents the probability of success for a certain experiment (binary outcome).\n",
    "- **Binomial Distribution**\n",
    "    - represents the probability of observing a specific number of successes (Bernoulli trials) in a specific number of trials.\n",
    "- **Poisson Distribution**\n",
    "    - represents the probability of ð‘› events in a given time period when the overall rate of occurrence is constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous\n",
    "\n",
    "With a continuous distribution, the set of possible results is an infinite set of values within a range. Think about measuring the length of something. The reported measurement can always be more or less precise.\n",
    "\n",
    "![](images/pdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of continuous distributions\n",
    "\n",
    "- **Continuous Uniform**;\n",
    "- **Normal or Gaussian**;\n",
    "- **Exponential**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMFs, PDFs, CDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF: Probability Mass Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\bf{probability\\ mass\\ function\\ (pmf)}$ for a random variable gives, at any value $k$, the probability that the random variable takes the value $k$. Suppose, for example, that I have a jar full of lottery balls containing:\n",
    "- 50 \"1\"s,\n",
    "- 25 \"2\"s,\n",
    "- 15 \"3\"s,\n",
    "- 10 \"4\"s\n",
    "\n",
    "We then represent this function in a plot like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number, we calculate the probability that pull it from the jar by dividing\n",
    "\n",
    "numbers = range(1, 5)\n",
    "counts = [50, 25, 15, 10]\n",
    "\n",
    "# calculate the probs by dividing each count by the total number of balls.\n",
    "\n",
    "probs = [count/sum(counts) for count in counts]\n",
    "\n",
    "lotto_dict = {number: prob for number, prob in zip(numbers, probs)}\n",
    "lotto_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot here!\n",
    "\n",
    "x = list(lotto_dict.keys())\n",
    "y = list(lotto_dict.values())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.plot(x, y, 'bo', ms=8, label='lotto pmf')\n",
    "ax.vlines(x, 0, y, 'r', lw=5)\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Value/Mean\n",
    "\n",
    "The expected value, or the mean, describes the 'center' of the distribution (you may hear this called the first moment).  The 'center' refers loosely to the middle-values of a distribution, and is measured more precisely by notions like the mean, the median, and the mode.\n",
    "\n",
    "For a discrete distribution, working from the vantage point of a collected sample of n data points:\n",
    "\n",
    "mean = $\\Large\\mu = \\frac{\\Sigma^n_{i = 1}x_i}{n}$\n",
    "\n",
    "If we are working from the vantage point of known probabilities, the mean is referred to as the expected value. The expected value of a discrete distribution is the weighted sum of all values of x, where the weight is their probability.\n",
    " \n",
    "The expected value of the Lotto example is:\n",
    "${\\displaystyle \\operatorname {E} [X]= \\Sigma^n_{i=1}p(x_i)x_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance/Standard Deviation\n",
    "Variance describes the spread of the data (it is also referred to as the second moment).  The 'spread' refers loosely to how far away the more extreme values are from the center.\n",
    "\n",
    "Standard deviation is the square root of variance, and effectively measures the *average distance away from the mean*.\n",
    "\n",
    "From the standpoint of a sample, the variance of a discrete distribution of n data points is:\n",
    "\n",
    "std = $\\Large\\sigma = \\sqrt{\\frac{\\Sigma^n_{i = 1}(x_i - \\mu)^2}{n}}$\n",
    "\n",
    "\n",
    "Variance is the expectation of the squared deviation of a random variable from its mean.\n",
    "\n",
    "For our Lotto PMF, that means:\n",
    "\n",
    " $ \\Large E((X-\\mu)^2) = \\sigma^2 = \\Sigma^n_{i=1}p(x_i)(x_i - \\mu)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uniform distribution describes a set of discrete outcomes whose probabilities are all equally likely.\n",
    "\n",
    "A common example is the roll of a die.  \n",
    "\n",
    "The pmf of a discrete uniform distribution is simply:\n",
    "\n",
    "$ f(x)=\\frac{1}{n} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected value for the roll of a 12-sided die\n",
    "\n",
    "expected_value = sum([1/12 * n for n in range(1, 13)])\n",
    "print(f'Expected value: {expected_value}')\n",
    "\n",
    "# variance for a roll of a 12-sided die\n",
    "\n",
    "variance = sum([1/12 * (n - expected_value)**2 for n in range(1, 13)])\n",
    "print(f'Variance: {variance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF: Probability Density Function\n",
    "\n",
    "> Probability density functions are similar to PMFs, in that they describe the probability of a result within a range of values. But where PMFs are appropriate for discrete variables and so can be descibed with barplots, PDFs are smooth curves that describe continuous random variables.  \n",
    "\n",
    "![](images/pdf_temp.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of a pdf as a bunch of bars of probabilities getting smaller and smaller until each neighbor is indistinguishable from its neighbor.\n",
    "\n",
    "It is then intuitive that you cannot calculate expected value and variance in the same way as we did with pmfs.  Instead, we have to integrate over the entirety of the curve to calculate the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected value and variance for PDFs:\n",
    "\n",
    "![](images/exp_v_pdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/pdf_inter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating the mean and standard deviation by hand, we will rather get familiar with how they affect the shape of our PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of our PDF affects where it is centered on the x-axis.  In `numpy` and `stats`, mean is denoted by the \"loc\" parameter.\n",
    "\n",
    "The two plots below have the same shape, but different centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 0\n",
    "z_curve = np.linspace(stats.norm(mean, 1).ppf(0.01),\n",
    "             stats.norm(mean, 1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, 1).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "z_curve = np.linspace(stats.norm(mean, 1).ppf(0.01),\n",
    "             stats.norm(mean, 1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, 1).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions differing in mean\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of our plots describes how closely the points are gathered around the mean.  Low variance means tight and skinny, high variance short and wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 1\n",
    "var = 1\n",
    "z_curve = np.linspace(stats.norm(mean, var).ppf(0.01),\n",
    "             stats.norm(mean, var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, var).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "var = 3\n",
    "z_curve = np.linspace(stats.norm(mean, var).ppf(0.01),\n",
    "             stats.norm(mean, var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, var).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions differing in variance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed Distributions\n",
    "\n",
    "Recall the third moment of a statistical distribution: skew. A skew of zero is perfectly symmetrical about the mean.   \n",
    "\n",
    "![skew](images/skew.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check skewness with scipy\n",
    "\n",
    "z_curve = np.random.normal(0, 1, 1000)\n",
    "print(stats.skew(z_curve))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming  Right/Positively Skewed Data\n",
    "\n",
    "We may want to transform our skewed data to make it approach symmetry.\n",
    "\n",
    "Common transformations of this data include \n",
    "\n",
    "##### Root Transformations:\n",
    "\n",
    "- $x \\rightarrow\\sqrt[n]{x}$\n",
    "\n",
    "##### Logarithmic Transformations:\n",
    "\n",
    "- $x \\rightarrow\\log_n{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Left/Negatively Skewed Data\n",
    "\n",
    "##### Power Transformations:\n",
    "\n",
    "- $x\\rightarrow x^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurtosis\n",
    "\n",
    "![kurtosis](images/kurtosis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDF: Cumulative Distribution Function\n",
    "\n",
    "![](images/cdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution function describes the probability that your result will be of a value equal to or below a certain value. It can apply to both discrete or continuous functions.\n",
    "\n",
    "For the scenario above, the CDF would describe the probability of drawing a ball equal to or below a certain number.  \n",
    "\n",
    "In order to create the CDF from a sample, we:\n",
    "- align the values from least to greatest\n",
    "- for each value, count the number of values that are less than or equal to the current value\n",
    "- divide that count by the total number of values\n",
    "\n",
    "The CDF of the Lotto example plots how likely we are to get a ball less than or equal to a given example. \n",
    "\n",
    "Let's create the CDF for our Lotto example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the values\n",
    "\n",
    "lotto_dict = {0:0, 1:50, 2:25, 3:15, 4:10}\n",
    "values = list(lotto_dict.keys())\n",
    "\n",
    "# count the number of values that are less than\n",
    "# or equal to the current value\n",
    "\n",
    "count_less_than_equal = np.cumsum(list(lotto_dict.values()))\n",
    "\n",
    "# divide by total number of values\n",
    "prob_less_than_or_equal = count_less_than_equal/sum(lotto_dict.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(values, prob_less_than_or_equal, 'bo', ms=8, label='lotto pdf')\n",
    "for i in range(0, 5):\n",
    "    ax.hlines(prob_less_than_or_equal[i], i,i+1, 'r', lw=5,)\n",
    "for i in range(0, 4):\n",
    "    ax.vlines(i+1, prob_less_than_or_equal[i+1],\n",
    "              prob_less_than_or_equal[i], linestyles='dotted')\n",
    "ax.legend(loc='best' )\n",
    "ax.set_ylim(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For continuous random variables, obtaining probabilities for observing a specific outcome is not possible \n",
    "- Be careful with interpretation of PDF\n",
    "\n",
    "We can use the CDF to learn the probability that a variable will be less than or equal to a given value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following normal distributions of heights (more on the normal distribution below).\n",
    "\n",
    "The PDF and the CDF look like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sorted(stats.norm.rvs(loc=70, scale=3, size=1000))\n",
    "r_cdf = stats.norm.cdf(r, loc=70, scale=3)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.kdeplot(r, ax=ax1, shade=True)\n",
    "ax1.set_title('PDF of Male Height in US')\n",
    "\n",
    "ax2.plot(r, r_cdf, color='g')\n",
    "ax2.set_title('CDF of Male Height in the US');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide `numpy` with the underlying parameters of our distribution, we can calculate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the probability that a value falls below a specified value\n",
    "\n",
    "r = stats.norm(70, 3)\n",
    "r.cdf(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the probability that a value falls between two specified values\n",
    "\n",
    "r = stats.norm(70, 3)\n",
    "r.cdf(73) - r.cdf(67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the value associated with a specfic percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.ppf(.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Discrete Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli and Binomial Distributions\n",
    "\n",
    "The Bernoulli Distribution is the discrete distribution that describes a two-outcome trial, such as a coin toss. The distribution is described by the probability $p$ of one random variable taking the value 1 and by the corrleative probability $q$, associated with 0 and taking the probability 1-p. \n",
    "\n",
    "PMF: \n",
    "${\\displaystyle {\\begin{cases}q=1-p&{\\text{if }}k=0\\\\p&{\\text{if }}k=1\\end{cases}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest example is, once again, a coin flip.  In this scenario, we define either heads or tails as a \"success\", and assume, if the coin is fair, the probability of success to be .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bernouli.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example would be a penalty kick in soccer.\n",
    "\n",
    "Let's assume the probability of scoring a goal is .75. Then the Bernoulli Distribution is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of scoring\n",
    "p = 0.75\n",
    "\n",
    "# probability of missing\n",
    "q = 1 - 0.75\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(['miss', 'score'],[q,p], color=['red','green'])\n",
    "ax.set_title('Bernouli Distribution of Penalty Kicks');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value is the probability of success, i.e. 0.75.\n",
    "\n",
    "The variance is:  \n",
    "$\\sigma^2 = (0.75)*(1-0.75) = 0.1875 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Binomial distribution describes the number of successes of a set of Bernoulli trials. For example, say we have an unfair coin with a probability of landing heads of 0.8. If our number of trials is 3, our PMF and CDF would look like what we see below:\n",
    "\n",
    "![](images/binomial.png)\n",
    "\n",
    "For the binomial, our Expected Value and Variance can be calculated like so:\n",
    "- Expected Value\n",
    "> $E(X) = np$ <br>\n",
    "- Variance\n",
    "> $Var(X) = np(1-p)$<br>\n",
    "\n",
    "If we want to see the probability of a certain number of successes, we use the pmf:<br/>\n",
    "$\\Large f(x) = {n \\choose k}p^k(1 - p)^{n - k}$\n",
    "\n",
    "Remember: ${n\\choose k} = \\frac{n!}{k!(n - k)!}$, the number of ways of choosing $k$ objects from a total of $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our penalty kick example. Suppose we consider a 10-kick set of penalty shots.\n",
    "\n",
    "The Binomial Distribution can tell me what the probability is that the shootout will result in exactly $k$ goals out of $n$ shots ($k < n$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "p = 0.75\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "x = np.arange(stats.binom.ppf(0.001, n, p),\n",
    "              stats.binom.ppf(0.999, n, p)+1)\n",
    "\n",
    "ax.plot(x, stats.binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\n",
    "ax.vlines(x, 0, stats.binom.pmf(x, n, p), 'r', linewidth=5,\n",
    "          label='pmf')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Distribution\n",
    "\n",
    "The Poisson distribution describes the probability of a certain number of a specific type of event occuring over a given interval. We assume that these events are probabilistically independent.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- number of visitors to a website over an hour\n",
    "- number of pieces of mail arriving at your door per day over a month\n",
    "- number of births in a hospital per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of the Poisson Distribution is governed by the rate parameter **$\\lambda$** (lambda):\n",
    "\n",
    "$\\Large\\lambda = \\frac{Avg\\ number\\ of\\ events}{period\\ of\\ time}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then our Poisson pmf is: ${\\displaystyle P(k)= {\\frac {\\lambda ^{k}e^{-\\lambda }}{k!}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the scenario where a website receives 100 hits per hour.\n",
    "\n",
    "Then we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 100\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "x = np.arange(stats.poisson.ppf(0.01, rate),\n",
    "              stats.poisson.ppf(0.99, rate))\n",
    "\n",
    "ax.plot(x, stats.poisson(rate).pmf(x), 'bo', ms=8, label='poisson pmf')\n",
    "ax.vlines(x, 0, stats.poisson(rate).pmf(x), 'r', linewidth=5,\n",
    "          label='Poisson Distribution:\\n Website Hits Over an Hour')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Poisson distribution has a unique characteristic:\n",
    "    \n",
    "$\\Large\\mu = \\sigma^2 = \\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The area under the curve up to the mean + 1sd\n",
    "# would be 84% of the total area\n",
    "\n",
    "stats.poisson.ppf(0.84, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution describes many phenomena. Think of anything that has a typical range:\n",
    "- human body temperatures\n",
    "- sizes of elephants\n",
    "- sizes of stars\n",
    "- populations of cities\n",
    "- IQ\n",
    "- heart rate\n",
    "\n",
    "Among human beings, 98.6 degrees Fahrenheit is an _average_ body temperature. Many folks' temperatures won't measure _exactly_ 98.6 degrees, but most measurements will be _close_. It is much more common to have a body temperature close to 98.6 (whether slightly more or slightly less) than it is to have a body temperature far from 98.6 (whether significantly more or significantly less). This is a hallmark of a normally distributed variable.\n",
    "\n",
    "Similarly, there are large elephants and there are small elephants, but most elephants are near the average size.\n",
    "\n",
    "The normal distribution is _very_ common in nature (**Why?**) and will arise often in your work. Get to know it well!\n",
    "\n",
    "You will recognize it by its characteristic bell curve. \n",
    "\n",
    "![normal_curve](images/IQ_normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see the notation \n",
    "\n",
    "$N(\\mu, \\sigma^2)$\n",
    "\n",
    "where N signifies that the distribution is normal, $\\mu$ is the mean, and $\\sigma^2$ is the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF of the normal curve is given by:\n",
    "\n",
    "$\\Large f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}exp\\left[\\frac{-(x - \\mu)^2}{2\\sigma^2}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mu = 0\n",
    "sigma = 1\n",
    "z_curve = np.linspace(stats.norm(mu,sigma).ppf(0.01),\n",
    "             stats.norm(mu,sigma).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mu,sigma).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/normal_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard normal distribution has a mean of 0 and variance of 1. This is also known as a z distribution. \n",
    "\n",
    "\n",
    "![norm_to_z](images/norm_to_z.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform the normal distribtion centered on 5\n",
    "# with a standard deviation of 2 into a standard normal\n",
    "\n",
    "normal_dist = np.random.normal(5, 2, 1000)\n",
    "z_dist = [(x - np.mean(normal_dist))/np.std(normal_dist) \n",
    "          for x in normal_dist]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(z_dist, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/empirical_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Rule\n",
    "\n",
    "> The Empirical or 68â€“95â€“99.7 Rule states that 68% of the values of a normal distribution of data lie within 1 standard deviation of the mean, 95% within 2 stds, and 99.7 within three.  \n",
    "> The empirical rule has many applications in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $z$-Score\n",
    "\n",
    "A $z$-score for a data point x (in a normal distribution) is simply the distance to the mean in units of standard deviations. That is:\n",
    "\n",
    "$z = \\frac{x - \\mu}{\\sigma}$.\n",
    "\n",
    "By calculating the z-score of an individual point, we can see how unlikely a value is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**:\n",
    "\n",
    "1. Consider the distribution of heights of American women, with a mean of 65 inches and a standard deviation of 3.5 inches.\n",
    "\n",
    "Calculate the z-score of a height of 75 inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What type of distribution would describe the following datasets?\n",
    "\n",
    "    - (a) results of rolling a die 100 times;\n",
    "    - (b) results of a random number generator;\n",
    "    - (c) results of random measurements of palm tree heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How would the salaries of New Yorkers likely be distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
